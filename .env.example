# ==========================================================
# ToolBridge Configuration
# ==========================================================

# ---------- Basic Configuration ----------
PORT=3000
PROXY_HOST=0.0.0.0
DEBUG_MODE=true

# ---------- Backend Configuration ----------
# Choose backend mode: "openai" or "ollama" 
BACKEND_MODE=openai

# For OpenAI-compatible backends (OpenAI, OpenRouter, etc.)
BACKEND_LLM_BASE_URL=https://api.openai.com/v1
BACKEND_LLM_API_KEY=sk-your-openai-api-key-here

# For Ollama backend (when BACKEND_MODE=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_API_KEY=

# ---------- Azure OpenAI Bridge Configuration ----------
# Azure OpenAI Data Plane (for inference calls)
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_RESOURCE=your-azure-openai-resource-name
AZURE_API_VERSION=2024-10-21

# Azure ARM (for deployment discovery)
AZURE_TENANT_ID=your-azure-tenant-id
AZURE_CLIENT_ID=your-azure-client-id
AZURE_CLIENT_SECRET=your-azure-client-secret
AZURE_SUBSCRIPTION_ID=your-azure-subscription-id
AZURE_RESOURCE_GROUP=your-resource-group-name
AZURE_ACCOUNT_NAME=your-cognitive-services-account-name

# OpenAI API (for Azure→OpenAI routing)
OPENAI_API_KEY=sk-your-openai-api-key-here

# ---------- Tool Configuration ----------
ENABLE_TOOL_REINJECTION=true
TOOL_REINJECTION_MESSAGE_COUNT=3
TOOL_REINJECTION_TOKEN_COUNT=1000
TOOL_REINJECTION_TYPE=system

# PASS_TOOLS controls whether original tools/tool_choice fields are sent to backend:
# - true: Keep original tool fields (backend receives them)  
# - false: Remove tool fields (some providers reject requests with unsupported tool fields)
# Note: Tool instructions are ALWAYS added to system messages regardless of this setting
PASS_TOOLS=true

# ---------- Performance Configuration ----------
MAX_BUFFER_SIZE=1048576
CONNECTION_TIMEOUT=120000
MAX_STREAM_BUFFER_SIZE=1048576
STREAM_CONNECTION_TIMEOUT=120000
MAX_TOOL_ITERATIONS=5

# ---------- Ollama Specific ----------
OLLAMA_DEFAULT_CONTEXT_LENGTH=4096

# ==========================================================
# Azure Bridge Usage Examples
# ==========================================================

# 1. OpenAI-style → Azure:
#    POST /bridge/v1/chat/completions
#    { "model": "gpt-4o", "messages": [...] }
#    → Routes to Azure deployment that has gpt-4o model

# 2. Azure-style → OpenAI:
#    POST /bridge/openai/deployments/my-gpt4o-deployment/chat/completions
#    { "messages": [...] }
#    → Routes to OpenAI with resolved model name

# 3. Health check:
#    GET /bridge/healthz
#    → Returns deployment discovery status

# ==========================================================
# Required Permissions for Azure ARM Discovery
# ==========================================================

# The service principal (CLIENT_ID/CLIENT_SECRET) needs:
# - Reader role on the Cognitive Services account
# - Microsoft.CognitiveServices/accounts/deployments/read permission

# To set up:
# 1. Create service principal: az ad sp create-for-rbac --name "toolbridge-sp"
# 2. Assign role: az role assignment create --assignee <client-id> --role "Cognitive Services User" --scope /subscriptions/<sub>/resourceGroups/<rg>/providers/Microsoft.CognitiveServices/accounts/<account>

# ==========================================================
