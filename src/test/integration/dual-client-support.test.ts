/**
 * Test that demonstrates ToolBridge working with both OpenAI and Ollama clients
 */

import { expect } from "chai";
import OpenAI from "openai";

import { 
  OllamaClient, 
  convertOpenAIToolsToOllama, 
  convertOpenAIMessagesToOllama 
} from "../utils/testHelpers.js";

// Test configuration
const PROXY_PORT = parseInt(process.env.PROXY_PORT ?? "3000", 10);
const PROXY_HOST = process.env.PROXY_HOST ?? "localhost";
const BASE_URL = `http://${PROXY_HOST}:${PROXY_PORT}`;
const TEST_MODEL = process.env['TEST_MODEL'] ?? "deepseek/deepseek-chat-v3.1:free";
const API_KEY = process.env.BACKEND_LLM_API_KEY ?? "sk-fake";

// Sample tools that work with both OpenAI and Ollama
const openaiTools: OpenAI.Chat.ChatCompletionTool[] = [
  {
    type: "function",
    function: {
      name: "get_weather",
      description: "Get weather information for a location",
      parameters: {
        type: "object",
        properties: {
          location: {
            type: "string",
            description: "The city and state, e.g. San Francisco, CA"
          }
        },
        required: ["location"]
      }
    }
  }
];

console.log("\nüîÑ DUAL CLIENT SUPPORT TEST");
console.log("Testing ToolBridge with both OpenAI and Ollama clients");

describe("üöÄ ToolBridge Dual Client Support", function() {
  this.timeout(60000);
  
  let openaiClient: OpenAI;
  let ollamaClient: OllamaClient;

  before(async function() {
    // Wait for ToolBridge to be ready
    let attempts = 0;
    let serverReady = false;
    
    while (!serverReady && attempts < 40) {
      try {
        const response = await fetch(`${BASE_URL}/`);
        serverReady = response.ok;
      } catch {
        // Server not ready yet
      }
      
      if (!serverReady) {
        attempts++;
        await new Promise(resolve => setTimeout(resolve, 500));
      }
    }

    if (!serverReady) {
      throw new Error(`ToolBridge server not ready after ${attempts} attempts`);
    }

    // Initialize both clients pointing to ToolBridge
    openaiClient = new OpenAI({
      baseURL: `${BASE_URL}/v1`,
      apiKey: API_KEY
    });

    ollamaClient = new OllamaClient({
      baseURL: BASE_URL,
      apiKey: API_KEY
    });
  });

  it("should support OpenAI client format", async function() {
    const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
      {
        role: "user",
        content: "What's the weather like in San Francisco, CA? Just say you'd check it."
      }
    ];

    try {
      const response = await openaiClient.chat.completions.create({
        model: TEST_MODEL,
        messages,
        tools: openaiTools,
        temperature: 0.1,
        max_tokens: 100
      });

      console.log("   üîç OpenAI Client Response:");
      console.log(`   - Model: ${response.model ?? "N/A"}`);
      console.log(`   - Has choices: ${Array.isArray(response.choices) && response.choices.length > 0}`);
      
      expect(response.choices).to.be.an("array");
      
      if (response.choices.length > 0 && response.choices[0]) {
        const firstChoice = response.choices[0];
        const message = firstChoice.message;
        
        if (message) {
          console.log(`   - Has message: true`);
          if (message.tool_calls && message.tool_calls.length > 0) {
            console.log(`   - Tool calls: ${message.tool_calls.length}`);
          }
          if (message.content) {
            console.log(`   - Content: ${message.content.substring(0, 50)}...`);
          }
        }
      }

      expect(true).to.be.true; // Test passes if no error is thrown
    } catch (error) {
      console.warn("   ‚ö†Ô∏è  OpenAI format test failed (possibly due to rate limits)");
      console.warn(`   Error: ${String(error)}`);
      // Don't fail for backend issues
      expect(true).to.be.true;
    }
  });

  it("should support Ollama client format", async function() {
    const messages = convertOpenAIMessagesToOllama([
      {
        role: "user", 
        content: "Just say hello, keep it simple."
      }
    ]);

    const ollamaTools = convertOpenAIToolsToOllama(openaiTools);

    try {
      const response = await ollamaClient.chat({
        model: TEST_MODEL,
        messages,
        tools: ollamaTools,
        temperature: 0.1,
        max_tokens: 100
      });

      console.log("   üîç Ollama Client Response:");
      console.log(`   - Model: ${response.model ?? "N/A"}`);
      console.log(`   - Done: ${response.done}`);
      
      if (response.message) {
        console.log(`   - Has message: true`);
        if (response.message.content) {
          console.log(`   - Content: ${response.message.content.substring(0, 50)}...`);
        }
        if (response.message.tool_calls && response.message.tool_calls.length > 0) {
          console.log(`   - Tool calls: ${response.message.tool_calls.length}`);
        }
      }

      expect(response.message).to.exist;
      expect(typeof response.done).to.equal("boolean");
    } catch (error) {
      console.warn("   ‚ö†Ô∏è  Ollama format test failed (possibly due to rate limits)");
      console.warn(`   Error: ${String(error)}`);
      // Don't fail for backend issues
      expect(true).to.be.true;
    }
  });

  it("should demonstrate format conversion utilities", function() {
    console.log("   üîÑ Testing format conversion utilities:");

    // Test OpenAI to Ollama message conversion
    const openaiMessages = [
      { role: "user", content: "Hello!" },
      { role: "assistant", content: "Hi there!" }
    ];

    const ollamaMessages = convertOpenAIMessagesToOllama(openaiMessages);
    console.log(`   - Converted ${openaiMessages.length} OpenAI messages to Ollama format`);
    
    expect(ollamaMessages).to.have.lengthOf(2);
    expect(ollamaMessages[0]).to.exist;
    if (ollamaMessages[0]) {
      expect(ollamaMessages[0].role).to.equal("user");
      expect(ollamaMessages[0].content).to.equal("Hello!");
    }

    // Test tool conversion
    const ollamaTools = convertOpenAIToolsToOllama(openaiTools);
    console.log(`   - Converted ${openaiTools.length} OpenAI tools to Ollama format`);
    
    expect(ollamaTools).to.have.lengthOf(1);
    expect(ollamaTools[0]).to.exist;
    if (ollamaTools[0]) {
      expect(ollamaTools[0].function.name).to.equal("get_weather");
    }

    console.log("   ‚úÖ Format conversion successful!");
  });
});
