/**
 * COMPLEX TOOL SCHEMAS END-TO-END TEST
 *
 * Tests ToolBridge's ability to handle complex tool schemas with:
 * - Deeply nested objects and arrays
 * - Large raw content preservation (HTML, code, markdown)
 * - Complex parameters (JSON strings, operations)
 * - Streaming with complex tools
 *
 * Validates XML parser and tool call conversion across all complexity levels.
 */

import { expect } from "chai";
import { before, after, describe, it } from "mocha";
import OpenAI from "openai";

import { setupTestServer, type TestServerSetup } from "../utils/testServerHelpers.js";
import { isRateLimitError, retryWithBackoff } from "../utils/retryHelpers.js";
import { TEST_MODEL_OPENAI_COMPATIBLE } from "../utils/testConfig.js";

const RUN_REAL_BACKEND_TESTS = process.env["RUN_REAL_BACKEND_TESTS"] === "true";
const describeReal = RUN_REAL_BACKEND_TESTS ? describe : describe.skip;

// ============================================================================
// SECTION 1: DEEPLY NESTED STRUCTURES
// ============================================================================

// Type definitions for plan_trip
interface PlanTripArgs {
  traveler: {
    name: string;
    age?: number;
    preferences?: {
      likes?: string[];
      newsletter?: boolean;
    };
  };
  destination: { city: string; country?: string };
  dates: { start: string; end: string };
  activities?: Array<{ type: string; cost?: number; options?: Record<string, unknown> }>;
  notes?: string;
}

interface PlanTripResult {
  itinerary_id: string;
  summary: string;
  estimate_usd: number;
  activities_planned: number;
}

const planTripTool: OpenAI.Chat.ChatCompletionTool = {
  type: "function",
  function: {
    name: "plan_trip",
    description: "Plan a complex trip with nested preferences and activities",
    parameters: {
      type: "object",
      properties: {
        traveler: {
          type: "object",
          properties: {
            name: { type: "string" },
            age: { type: "number" },
            preferences: {
              type: "object",
              properties: {
                likes: { type: "array", items: { type: "string" } },
                newsletter: { type: "boolean" },
              },
            },
          },
          required: ["name"],
        },
        destination: {
          type: "object",
          properties: { city: { type: "string" }, country: { type: "string" } },
          required: ["city"],
        },
        dates: {
          type: "object",
          properties: { start: { type: "string" }, end: { type: "string" } },
          required: ["start", "end"],
        },
        activities: {
          type: "array",
          items: {
            type: "object",
            properties: {
              type: { type: "string" },
              cost: { type: "number" },
              options: { type: "object" },
            },
            required: ["type"],
          },
        },
        notes: { type: "string" },
      },
      required: ["traveler", "destination", "dates"],
    },
  },
};

const ingestDatasetTool: OpenAI.Chat.ChatCompletionTool = {
  type: "function",
  function: {
    name: "ingest_dataset",
    description: "Ingest complex dataset with nested objects, arrays, and metadata",
    parameters: {
      type: "object",
      properties: {
        meta: {
          type: "object",
          properties: {
            name: { type: "string" },
            version: { type: "string" },
            tags: { type: "array", items: { type: "string" } },
            flags: { type: "object", properties: { dryRun: { type: "boolean" }, upsert: { type: "boolean" } } },
          },
          required: ["name"],
        },
        records: {
          type: "array",
          items: {
            type: "object",
            properties: {
              id: { type: "string" },
              attrs: { type: "object" },
              values: { type: "array", items: { type: "number" } },
            },
            required: ["id"],
          },
        },
        notes: { type: "string" },
      },
      required: ["meta", "records"],
    },
  },
};

// ============================================================================
// SECTION 2: LARGE RAW CONTENT PRESERVATION
// ============================================================================

interface GenerateDocArgs {
  title: string;
  markdown?: string;
  code?: string;
  html?: string;
}

interface GenerateDocResult {
  document_id: string;
  title: string;
  sizes: { markdown: number; code: number; html: number };
}

const renderReportTool: OpenAI.Chat.ChatCompletionTool = {
  type: "function",
  function: {
    name: "render_report",
    description: "Render a large report with raw HTML/markdown/code. Preserve raw content.",
    parameters: {
      type: "object",
      properties: {
        title: { type: "string" },
        html: { type: "string" },
        markdown: { type: "string" },
        code: { type: "string" },
      },
      required: ["title"],
    },
  },
};

const generateDocumentTool: OpenAI.Chat.ChatCompletionTool = {
  type: "function",
  function: {
    name: "generate_document",
    description: "Generate a document; large raw payloads allowed in markdown/code/html",
    parameters: {
      type: "object",
      properties: {
        title: { type: "string" },
        markdown: { type: "string" },
        code: { type: "string" },
        html: { type: "string" },
      },
      required: ["title"],
    },
  },
};

// ============================================================================
// SECTION 3: COMPLEX PARAMETERS
// ============================================================================

interface TransformDataArgs {
  json: string; // raw JSON string
  operations?: string[];
}

interface TransformDataResult {
  ok: boolean;
  keys: string[];
  op_count: number;
}

const transformDataTool: OpenAI.Chat.ChatCompletionTool = {
  type: "function",
  function: {
    name: "transform_data",
    description: "Transform JSON-like data with a sequence of operations",
    parameters: {
      type: "object",
      properties: {
        json: { type: "string" },
        operations: { type: "array", items: { type: "string" } },
      },
      required: ["json"],
    },
  },
};

// ============================================================================
// FUNCTION IMPLEMENTATIONS
// ============================================================================

type AvailableFn =
  | ((a: PlanTripArgs) => Promise<PlanTripResult>)
  | ((a: GenerateDocArgs) => Promise<GenerateDocResult>)
  | ((a: TransformDataArgs) => Promise<TransformDataResult>);

const functions: Record<string, AvailableFn> = {
  plan_trip: async (args: PlanTripArgs): Promise<PlanTripResult> => {
    const activities = args.activities ?? [];
    const estimate = activities.reduce((sum, a) => sum + (typeof a.cost === "number" ? a.cost : 0), 0);
    await Promise.resolve();
    return {
      itinerary_id: `it_${Date.now()}`,
      summary: `${args.traveler.name} ‚Üí ${args.destination.city} (${args.dates.start} ‚Üí ${args.dates.end})`,
      estimate_usd: Math.round(estimate * 100) / 100,
      activities_planned: activities.length,
    };
  },

  generate_document: async (args: GenerateDocArgs): Promise<GenerateDocResult> => {
    await Promise.resolve();
    return {
      document_id: `doc_${Date.now()}`,
      title: args.title,
      sizes: {
        markdown: (args.markdown ?? "").length,
        code: (args.code ?? "").length,
        html: (args.html ?? "").length,
      },
    };
  },

  transform_data: async (args: TransformDataArgs): Promise<TransformDataResult> => {
    await Promise.resolve();
    let obj: Record<string, unknown> = {};
    try { obj = JSON.parse(args.json); } catch { /* keep empty */ }
    return {
      ok: true,
      keys: Object.keys(obj),
      op_count: (args.operations ?? []).length,
    };
  },
};

// ============================================================================
// TEST SUITES
// ============================================================================

describeReal("üß™ Complex Tool Schemas E2E", function () {
  this.timeout(120000);

  let server: TestServerSetup;
  let openai: OpenAI;
  const TEST_MODEL = TEST_MODEL_OPENAI_COMPATIBLE;
  const API_KEY = process.env.BACKEND_LLM_API_KEY ?? "sk-test";

  const runWithRetry = async <T>(fn: () => Promise<T>, maxRetries = 5): Promise<T> => {
    return retryWithBackoff(fn, {
      maxRetries,
      baseDelayMs: 1000,
      maxDelayMs: 10000,
      shouldRetry: (error) => isRateLimitError(error),
      onRetry: (error, attempt, delayMs) => {
        if (isRateLimitError(error)) {
          console.warn(`   ‚è≥  429 on attempt ${attempt + 1}, retrying after ${delayMs}ms...`);
        }
      },
    });
  };

  const callOrNeutral = async <T>(fn: () => Promise<T>): Promise<T | null> => {
    try {
      return await retryWithBackoff(fn, {
        maxRetries: 1,
        baseDelayMs: 800,
        maxDelayMs: 800,
        shouldRetry: (error) => isRateLimitError(error),
        onRetry: () => {
          console.warn("   ‚è≥  429 encountered, retrying after 800ms...");
        },
      });
    } catch (error: unknown) {
      if (isRateLimitError(error)) {
        console.warn("   ‚ö†Ô∏è  Persistent backend 429 rate limit; neutral pass.");
        return null;
      }
      if (error instanceof Error) {
        throw error;
      }
      throw new Error(String(error));
    }
  };

  before(async function () {
    server = await setupTestServer({
      readinessPath: "/v1/models",
    });
    openai = new OpenAI({ baseURL: server.openaiBaseUrl, apiKey: API_KEY });
  });

  after(async function () {
    await server.cleanup();
  });

  // ============================================================================
  // SECTION 1: DEEPLY NESTED STRUCTURES
  // ============================================================================

  describe("1Ô∏è‚É£ Deeply Nested Structures", () => {
    it("handles nested/array-heavy plan_trip tool call end-to-end", async function () {
      const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
        { role: "user", content: "Plan a 10-day Tokyo trip for Jane Doe. Include a food tour and a museum visit." },
      ];

      const resp = await callOrNeutral(async () => openai.chat.completions.create({
        model: TEST_MODEL,
        messages,
        tools: [planTripTool],
        temperature: 0.1,
        max_tokens: 600
      }));
      if (!resp) { return; }
      const msg = resp.choices?.[0]?.message;
      if (!msg) { return; }

      // Proxy must convert XML to tool_calls - if content has XML, proxy failed
      if (!msg.tool_calls || msg.tool_calls.length === 0) {
        if (typeof msg.content === "string" && msg.content.includes("<plan_trip>")) {
          throw new Error("Proxy returned XML in content instead of tool_calls - translation layer failed");
        }
        console.warn("   ‚ÑπÔ∏è  No tool call generated. Neutral.");
        return;
      }

      const toolCall = msg.tool_calls[0];
      if (!toolCall?.function) {
        console.warn("   ‚ÑπÔ∏è  Tool call missing function. Neutral.");
        return;
      }

      const fnName = toolCall.function.name;
      const args = JSON.parse(toolCall.function.arguments) as PlanTripArgs;

      expect(fnName).to.equal("plan_trip");
      expect(args).to.not.equal(null);

      // Normalize potential shapes for activities
      const normalizeActivities = (v: unknown): Array<{ type: string; cost?: number; options?: Record<string, unknown> }> => {
        if (!v) {return [];}
        if (Array.isArray(v)) {
          return v.filter(item =>
            typeof item === 'object' &&
            item !== null &&
            'type' in item &&
            typeof (item as Record<string, unknown>)['type'] === 'string'
          ).map(item => item as { type: string; cost?: number; options?: Record<string, unknown> });
        }
        if (typeof v === "object") {
          const o = v as Record<string, unknown>;
          const inner = o['item'] ?? o['activity'] ?? o['items'] ?? o['entries'] ?? null;
          if (!inner) {return [];}
          return normalizeActivities(inner);
        }
        return [];
      };

      const argsObj = args as unknown as Record<string, unknown>;
      const normalized: PlanTripArgs = {
        traveler: argsObj['traveler'] as PlanTripArgs['traveler'],
        destination: argsObj['destination'] as PlanTripArgs['destination'],
        dates: argsObj['dates'] as PlanTripArgs['dates'],
        activities: normalizeActivities(argsObj['activities']),
      };

      const notes = argsObj['notes'] as string | undefined;
      if (notes !== undefined) normalized.notes = notes;

      expect(normalized.destination?.city?.toLowerCase?.()).to.include("tokyo");

      const result = await (functions["plan_trip"] as (a: PlanTripArgs) => Promise<PlanTripResult>)(normalized);
      expect(result.itinerary_id).to.be.a("string");
      expect(result.summary.toLowerCase()).to.include("tokyo");

      if (result.activities_planned === 0) {
        console.warn(`[WARN] No activities were planned - likely a model variation`);
      } else {
        expect(result.activities_planned).to.be.greaterThan(0);
      }
    });

    it("handles deeply nested arrays/objects in ingest_dataset", async function () {
      const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
        {
          role: "system",
          content: `You are an AI assistant with access to tools. When using tools, you MUST wrap your tool calls in the following format:

<toolbridge_calls>
<tool_name>
  <param1>value1</param1>
  <param2>value2</param2>
</tool_name>
</toolbridge_calls>

This wrapper format is REQUIRED for the system to detect and execute your tool calls properly.`
        },
        {
          role: "user",
          content: "Ingest dataset named 'customers' v1 with two records and dryRun=true; include tags A,B"
        },
      ];

      let resp;
      try {
        resp = await runWithRetry(async () => openai.chat.completions.create({
          model: TEST_MODEL,
          messages,
          tools: [ingestDatasetTool],
          temperature: 0.1,
          max_tokens: 400
        }), 3);
      } catch (e: unknown) {
        const msg = e instanceof Error ? e.message : String(e);
        if (msg.includes("429") || /rate limit/i.test(msg) || msg.includes("Exceeded maximum retries")) {
          console.warn(`   ‚ö†Ô∏è  Skipping test due to rate limiting: ${msg}`);
          this.skip();
          return;
        }
        throw e;
      }
      const msg = resp.choices?.[0]?.message;
      if (!msg) {
        console.warn("   ‚ÑπÔ∏è  No response message received. Neutral.");
        return;
      }

      // Proxy must convert XML to tool_calls
      if (!msg.tool_calls || msg.tool_calls.length === 0) {
        if (msg.content && typeof msg.content === "string" && msg.content.includes("<ingest_dataset>")) {
          throw new Error("Proxy returned XML in content instead of tool_calls - translation layer failed");
        }
        console.warn("   ‚ÑπÔ∏è  No tool call generated. Neutral.");
        return;
      }

      const tc = msg.tool_calls[0];
      if (!tc?.function) {
        console.warn("   ‚ÑπÔ∏è  Tool call missing function. Neutral.");
        return;
      }

      const toolUsed = true;
      const parsedArgs = JSON.parse(tc.function.arguments);
      const toolName = tc.function.name;

      if (toolUsed) {
        expect(toolName, "ToolBridge must detect the correct tool name").to.equal("ingest_dataset");
        expect(parsedArgs, "ToolBridge must parse tool arguments").to.not.be.null;
        expect(typeof parsedArgs, "ToolBridge must extract structured arguments").to.equal("object");
      } else {
        expect(msg.content && typeof msg.content === "string", "Assistant should return a valid textual response when not using tools").to.be.true;
        expect((msg.content as string).length, "Textual response should not be empty").to.be.greaterThan(0);
      }

      if (toolUsed && parsedArgs !== null && typeof parsedArgs === "object") {
        const argsObj = parsedArgs as Record<string, unknown>;
        if (argsObj['meta'] && typeof argsObj['meta'] === "object") {
          expect(typeof argsObj['meta'], "ToolBridge must preserve nested meta object structure").to.equal("object");
        }
        if (argsObj['records']) {
          const records = Array.isArray(argsObj['records']) ? argsObj['records'] : [argsObj['records']];
          expect(records.length, "ToolBridge must preserve all record structures").to.be.greaterThan(0);
          expect(records.every((r: unknown) => typeof r === "object" && r !== null), "All records must be valid objects").to.be.true;
        }
      }
    });
  });

  // ============================================================================
  // SECTION 2: LARGE RAW CONTENT PRESERVATION
  // ============================================================================

  describe("2Ô∏è‚É£ Large Raw Content Preservation", () => {
    it("handles raw HTML/code/markdown in generate_document", async function () {
      const largeHtml = '<!DOCTYPE html><html><head><script>if(a<3){console.log(1)}</script></head><body><div>Ok</div></body></html>';
      const largeCode = 'function x(a,b){return a+b} // '.repeat(50);
      const largeMd = '# Title\n\n**Bold** _Italics_'.repeat(20);
      const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
        { role: "user", content: "Generate a document titled 'Q4 Report' including markdown summary, code sample, and HTML preview." },
      ];

      async function getFirstToolCall(): Promise<{ fnName: string | null; args: GenerateDocArgs | null; msg: OpenAI.Chat.Completions.ChatCompletionMessage }> {
        const r = await openai.chat.completions.create({
          model: TEST_MODEL,
          messages,
          tools: [generateDocumentTool],
          temperature: 0.1,
          max_tokens: 600
        });
        const m = r.choices?.[0]?.message;
        if (!m) {
          throw new Error('No message received');
        }
        let fnName: string | null = null;
        let args: GenerateDocArgs | null = null;
        // Integration test: Proxy MUST convert XML ‚Üí tool_calls
        if (!m.tool_calls || m.tool_calls.length === 0) {
          if (typeof m.content === "string" && m.content.includes("<generate_document>")) {
            throw new Error("PROXY FAILURE: Returned XML in content instead of tool_calls - translation layer not working");
          }
          return { fnName: null, args: null, msg: m };
        }

        const toolCall = m.tool_calls[0];
        if (!toolCall?.function) {
          return { fnName: null, args: null, msg: m };
        }

        fnName = toolCall.function.name;
        try {
          args = JSON.parse(toolCall.function.arguments) as GenerateDocArgs;
        } catch (e) {
          console.warn(`[WARN] Failed to parse tool call arguments: ${e instanceof Error ? e.message : String(e)}`);
          args = null;
        }

        return { fnName, args, msg: m };
      }

      let { fnName, args } = await getFirstToolCall();
      if (fnName !== "generate_document" || !args) {
        messages.unshift({ role: "system", content: "Reminder: if a tool is suitable, call generate_document using the XML wrapper as instructed." });
        ({ fnName, args } = await getFirstToolCall());
      }

      if (fnName !== "generate_document" || !args) {
        return;
      }

      args.html = args.html ?? largeHtml;
      args.code = args.code ?? largeCode;
      args.markdown = args.markdown ?? largeMd;

      const result = await (functions["generate_document"] as (a: GenerateDocArgs) => Promise<GenerateDocResult>)(args);
      expect(result.document_id).to.be.a("string");
      expect(result.title.toLowerCase()).to.include("q4");
    });

    it("preserves large raw HTML/code/markdown in render_report", async function () {
      const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
        {
          role: "system",
          content: `You are an AI assistant with access to tools. When using tools, you MUST wrap your tool calls in the following format:

<toolbridge_calls>
<tool_name>
  <param1>value1</param1>
  <param2>value2</param2>
</tool_name>
</toolbridge_calls>

This wrapper format is REQUIRED for the system to detect and execute your tool calls properly.`
        },
        {
          role: "user",
          content: "Render a report named 'Complex Q4'. Include raw HTML with <script>, markdown, and a code block."
        },
      ];

      let resp;
      try {
        resp = await runWithRetry(async () => openai.chat.completions.create({
          model: TEST_MODEL,
          messages,
          tools: [renderReportTool],
          temperature: 0.1,
          max_tokens: 600
        }), 3);
      } catch (e: unknown) {
        const msg = e instanceof Error ? e.message : String(e);
        if (msg.includes("429") || /rate limit/i.test(msg) || msg.includes("Exceeded maximum retries")) {
          console.warn(`   ‚ö†Ô∏è  Skipping test due to rate limiting: ${msg}`);
          this.skip();
          return;
        }
        throw e;
      }
      const msg = resp.choices?.[0]?.message;
      if (!msg) {
        console.warn("   ‚ÑπÔ∏è  No response message received. Neutral.");
        return;
      }

      let toolUsed = false;
      let parsedArgs: unknown = null;
      let toolName: string | null = null;

      // Integration test: Proxy MUST convert XML ‚Üí tool_calls
      if (!msg.tool_calls || msg.tool_calls.length === 0) {
        if (msg.content && typeof msg.content === "string" && msg.content.includes("<render_report>")) {
          throw new Error("PROXY FAILURE: Returned XML in content instead of tool_calls - translation layer not working");
        }
        console.warn("   ‚ÑπÔ∏è  No tool call generated. Neutral.");
        return;
      }

      const tc = msg.tool_calls[0];
      if (!tc?.function) {
        console.warn("   ‚ÑπÔ∏è  Tool call missing function. Neutral.");
        return;
      }

      toolUsed = true;
      try {
        parsedArgs = JSON.parse(tc.function.arguments);
      } catch (e) {
        console.warn(`   ‚ö†Ô∏è  Failed to parse tool call arguments: ${e instanceof Error ? e.message : String(e)}`);
        console.warn(`   Arguments string: ${tc.function.arguments?.substring(0, 200)}...`);
        return;
      }
      toolName = tc.function.name;

      if (toolUsed) {
        expect(toolName).to.equal("render_report");
        expect(parsedArgs).to.not.be.null;
        if (parsedArgs !== null && typeof parsedArgs === 'object') {
          const argsObj = parsedArgs as Record<string, unknown>;
          if (argsObj['html']) {
            const htmlStr = typeof argsObj['html'] === "string" ? argsObj['html'] : JSON.stringify(argsObj['html']);
            const hasRawHtml = /<!DOCTYPE\s+html|<html\b|<body\b|<div\b|<script\b|<style\b/i.test(htmlStr) || htmlStr.includes("<![CDATA[");
            expect(hasRawHtml, `ToolBridge should preserve raw HTML; got: ${htmlStr.substring(0, 120)}...`).to.be.true;
            expect(htmlStr).to.not.include("&lt;div&gt;");
          }
        }
      } else {
        const content = msg.content ?? "";
        expect(typeof content).to.equal("string");
        expect((content).length).to.be.greaterThan(0);
      }
    });
  });

  // ============================================================================
  // SECTION 3: COMPLEX PARAMETERS
  // ============================================================================

  describe("3Ô∏è‚É£ Complex Parameters (JSON strings, operations)", () => {
    it("handles transform_data with operations array and JSON payload", async function () {
      const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
        { role: "user", content: "Normalize and dedupe this record: {\"name\":\"ACME\",\"count\":3}" },
      ];

      const tryOnce = async () => {
        const resp = await openai.chat.completions.create({
          model: TEST_MODEL,
          messages,
          tools: [transformDataTool],
          temperature: 0.1,
          max_tokens: 400
        });
        const msg = resp.choices?.[0]?.message;
        if (!msg) {
          throw new Error('No message received');
        }
        let fnName: string | null = null;
        let args: TransformDataArgs | null = null;
        // Integration test: Proxy MUST convert XML ‚Üí tool_calls
        if (!msg.tool_calls || msg.tool_calls.length === 0) {
          if (typeof msg.content === "string" && msg.content.includes("<transform_data>")) {
            throw new Error("PROXY FAILURE: Returned XML in content instead of tool_calls - translation layer not working");
          }
          return { fnName: null, args: null, msg };
        }

        const toolCall = msg.tool_calls[0];
        if (!toolCall?.function) {
          return { fnName: null, args: null, msg };
        }

        fnName = toolCall.function.name;
        args = JSON.parse(toolCall.function.arguments) as TransformDataArgs;

        return { fnName, args, msg };
      };

      let { fnName, args } = await callOrNeutral(tryOnce) ?? { fnName: null as string | null, args: null as TransformDataArgs | null };
      if (fnName !== "transform_data" || !args) {
        messages.unshift({ role: "system", content: "If using a tool is suitable, call transform_data using the XML wrapper as instructed." });
        ({ fnName, args } = (await callOrNeutral(tryOnce)) ?? { fnName: null as string | null, args: null as TransformDataArgs | null });
      }

      if (fnName !== "transform_data" || !args) {
        return;
      }

      args.operations ??= ["normalize", "dedupe"];
      const result = await (functions["transform_data"] as (a: TransformDataArgs) => Promise<TransformDataResult>)(args);
      expect(result.ok).to.equal(true);
      expect(result.keys.length).to.be.greaterThan(0);
    });
  });

  // ============================================================================
  // SECTION 4: STREAMING WITH COMPLEX TOOLS
  // ============================================================================

  describe("4Ô∏è‚É£ Streaming with Complex Tools", () => {
    it("streams tool calls and wrapper-aware processor converts to tool_calls", async function () {
      const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
        {
          role: "system",
          content: `You are an AI assistant with access to tools. When using tools, you MUST wrap your tool calls in the following format:

<toolbridge_calls>
<tool_name>
  <param1>value1</param1>
  <param2>value2</param2>
</tool_name>
</toolbridge_calls>

This wrapper format is REQUIRED for the system to detect and execute your tool calls properly.`
        },
        {
          role: "user",
          content: "Create a minimal render_report call for title 'Mini'"
        },
      ];

      let stream;
      try {
        stream = await runWithRetry(async () => openai.chat.completions.create({
          model: TEST_MODEL,
          messages,
          tools: [renderReportTool],
          stream: true,
          temperature: 0.1
        }), 3);
      } catch (e: unknown) {
        const msg = e instanceof Error ? e.message : String(e);
        if (msg.includes("429") || /rate limit/i.test(msg) || msg.includes("Exceeded maximum retries")) {
          console.warn(`   ‚ö†Ô∏è  Skipping test due to rate limiting: ${msg}`);
          this.skip();
          return;
        }
        throw e;
      }

      let toolName: string | null = null;
      let argBuf = "";
      let contentBuf = "";
      let chunkCount = 0;

      try {
        const streamTimeout = 30000;
        const timeoutPromise = new Promise((_, reject) =>
          setTimeout(() => reject(new Error("Stream consumption timeout")), streamTimeout)
        );

        const consumeStream = async () => {
          for await (const chunk of stream) {
            chunkCount++;
            if (chunk.choices?.[0]?.delta) {
              const delta = chunk.choices[0].delta;

              const tcs = delta.tool_calls;
              if (tcs) {
                for (const d of tcs) {
                  if (d.function?.name) {toolName = d.function.name;}
                  if (d.function?.arguments) {argBuf += d.function.arguments;}
                }
              }

              if (delta.content) {
                contentBuf += delta.content;
              }
            }
          }
        };

        await Promise.race([consumeStream(), timeoutPromise]);
      } catch (streamError: unknown) {
        const msg = streamError instanceof Error ? streamError.message : String(streamError);
        console.error(`   ‚ùå  Stream error: ${msg}`);

        if (msg.includes("timeout") || msg.includes("Socket") || msg.includes("ETIMEDOUT") || msg.includes("ECONNRESET")) {
          console.warn(`   ‚ö†Ô∏è  Skipping test due to stream timeout/connection issue`);
          this.skip();
          return;
        }
        throw streamError;
      }

      if (process.env.DEBUG_MODE === "true") {
        console.log(`   üìä  Chunks: ${chunkCount}, Tool: ${toolName}, Content length: ${contentBuf.length}`);
        if (contentBuf) console.log(`   üìÑ  Content: ${contentBuf.substring(0, 50)}...`);
      }

      let parsedArgs: unknown = null;
      let toolUsed = false;

      // Integration test: Proxy MUST convert XML ‚Üí tool_calls in streaming
      if (toolName && argBuf) {
        parsedArgs = JSON.parse(argBuf);
        toolUsed = true;
      } else if (contentBuf && contentBuf.includes("<render_report>")) {
        throw new Error("PROXY FAILURE: Stream returned XML in content instead of tool_calls - translation layer not working");
      }

      if (toolUsed) {
        expect(toolName, "Tool name should be present when tools are used").to.be.oneOf(["render_report", "ingest_dataset"]);
        expect(parsedArgs, "Arguments should be an object when tools are used").to.be.an("object");
        if (argBuf) {
          const args = JSON.parse(argBuf);
          expect(args).to.be.an("object");
        }
      } else {
        expect(chunkCount, "Stream should yield at least one chunk").to.be.greaterThan(0);
      }
    });
  });
});
